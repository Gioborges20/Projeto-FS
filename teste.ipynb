{
 "cells": [
  {
   "cell_type": "code",
   "id": "92232e28-f666-49fc-98f0-757cca6985a3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-30T23:12:59.664518Z"
    }
   },
   "source": [
    "%pip install --upgrade pip \n",
    "%pip install -U langchain  \n",
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph  \n",
    "%pip install -qU \"langchain[mistralai]\" \n",
    "%pip install -qU langchain-huggingface\n",
    "%pip install sentence-transformers\n",
    "%pip install -qU langchain-core\n",
    "%pip install -qU langchain_community pypdf pillow"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.67)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hanna\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "INDEXING",
   "id": "0137f8e4-ce47-4172-8ee8-7d192410eee9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:32:17.095818Z",
     "start_time": "2025-06-30T22:32:17.091039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "from dotenv import load_dotenv,find_dotenv"
   ],
   "id": "7ca185d467ce0d59",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:46:50.764584Z",
     "start_time": "2025-06-30T22:46:47.211816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# langsmith e os e getpass para lidar com as chaves de api\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key fot langsmith: \")"
   ],
   "id": "f612dd9b-ad9b-4a98-bbb9-0447ecba22ab",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:10:01.780171Z",
     "start_time": "2025-06-30T23:10:00.949797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# chat model\n",
    "if not os.environ.get(\"MISTRAL_API_KEY\"):\n",
    "  os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter API key for Mistral AI: \")\n",
    "\n",
    "llm = init_chat_model(\"mistral-small-2503\", model_provider = \"mistralai\")"
   ],
   "id": "5c51b92e-83f0-435d-b3c6-4adf0b04d934",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "11d7f531-73b1-442b-92a5-9c533c8b246a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# vector in-memory\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ],
   "id": "ec76efa7-f47f-4a37-94f6-def3bd8fc71d"
  },
  {
   "cell_type": "code",
   "id": "a6bee90f-9e81-4de9-81a2-3c687a78b9f4",
   "metadata": {},
   "source": [
    "# Loading documents em pdf\n",
    "directory_path = (\n",
    "    \"C:/JupyterNotebook/RAG/RAG_exames\"\n",
    ")\n",
    "loader = PyPDFDirectoryLoader(\"RAG_exames/\")\n",
    "\n",
    "docs = loader.load()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a45c7a-5050-4b11-997b-13a72eb78526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split pdf into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b04f0-f241-4dfa-9877-864c7f44bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing documents\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80349158-de62-4f53-8733-102304f806d3",
   "metadata": {},
   "source": [
    "INICIO DO RETRIEVAL E GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "id": "f73a7927-d6b1-4654-9d81-d3f447136507",
   "metadata": {},
   "source": [
    "# prompt\n",
    "# fazer teste em txt\n",
    "template = \"\"\"Você é um especialista em análise de relatórios de mamografia. Por favor, leia o relatório quando indicado e extraia as seguintes informações:\n",
    "Cisto:\n",
    "- Presente ou Ausente\n",
    "- Localização e tamanho do cisto\n",
    "Nódulo:\n",
    "- Presente ou Ausente\n",
    "- Localização e tamanho do nódulo\n",
    "Calcificação:\n",
    "- Presente ou Ausente\n",
    "- Localização e tamanho da calcificação\n",
    "Microcalcificação:\n",
    "- Presente ou Ausente\n",
    "- Localização e tamanho da microcalcificação\n",
    "BI-RADS: [valor]\n",
    "Outras citações a avaliar: [observações adicionais relevantes]\n",
    "\n",
    "Caso não encontre alguma informação que se encaixe, coloque [sem referência no texto].\n",
    "\n",
    "Diretrizes de Interpretação\n",
    "\n",
    "Diferenciação entre Nódulo e Cisto:\n",
    "\n",
    "Se um achado é identificado inicialmente como \"nódulo\" na mamografia, mas confirmado como \"cisto\" no ultrassom, classifique apenas como CISTO (presente).\n",
    "Nódulos são estruturas sólidas; cistos são estruturas predominantemente líquidas.\n",
    "Complexos sólido-císticos devem ser reportados em ambas categorias (nódulo E cisto).\n",
    "\n",
    "\n",
    "Priorização de Achados Múltiplos:\n",
    "\n",
    "Quando houver múltiplos cistos/nódulos, reporte TODOS, priorizando:\n",
    "a) Achados classificados como suspeitos pelo relatório\n",
    "b) Achados de maior tamanho\n",
    "c) Achados com características atípicas mencionadas\n",
    "\n",
    "\n",
    "Diferenciação entre Calcificações e Microcalcificações:\n",
    "\n",
    "Calcificações: estruturas maiores, geralmente descritas como \"grosseiras\", \"distróficas\", \"vasculares\"\n",
    "Microcalcificações: estruturas menores, frequentemente descritas como \"puntiformes\", \"pleomórficas\", \"lineares\", \"agrupadas\", \"em cluster\"\n",
    "Se o relatório mencionar \"microcalcificações\", classifique especificamente como microcalcificações\n",
    "Se mencionar apenas \"calcificações\", classifique como calcificações.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# estado para o langgraph\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ],
   "id": "754230c01b5fb7d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Funções do rag\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = custom_rag_prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ],
   "id": "f3ccb811c0b2d3c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# langgraph\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "c3ae2304570507f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
